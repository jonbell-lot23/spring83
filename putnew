#!/usr/bin/env node

'use strict';

const fs = require('fs');
const path = require('path');
const cheerio = require('cheerio');
const { fetch } = require('undici');
const ed = require('@noble/ed25519');
const { minify } = require('html-minifier-terser');
const { constants, findKnownKeys } = require('./common');

const umsDate = new Date();

async function preprocess (htmlFileBytes, pubKeyHex) {
  const htmlParsed = cheerio.load(htmlFileBytes);

  // append required <time> tag if not already present
  if (htmlParsed('time').length === 0) {
    const ogByteLen = htmlFileBytes.length;
    htmlParsed('html').append(`<time datetime="${umsDate.toISOString().replace(/\.\d{3}Z$/, 'Z')}">`);
    htmlFileBytes = Buffer.from(htmlParsed.root().html(), 'utf8');
    console.log(`${pubKeyHex}.html: appended <time>, which added ${htmlFileBytes.length - ogByteLen} bytes`);
  }

  const preMiniByteLen = htmlFileBytes.length;
  // htmlFileBytes = Buffer.from(await minify(htmlFileBytes.toString('utf8'), constants.putnewMinifyOptions), 'utf8');
  const minifiedBytes = preMiniByteLen - htmlFileBytes.length;

  if (htmlFileBytes.length > constants.maximumContentLength) {
    console.error(`${pubKeyHex}.html: ERRRO, still too large! By ` +
      `${htmlFileBytes.length - constants.maximumContentLength} bytes (${htmlFileBytes.length})!`);
    process.exit(-1);
  }

  console.log(`${pubKeyHex}.html: minified ${Number((minifiedBytes / preMiniByteLen) * 100).toFixed(0)}%` +
    ` (${minifiedBytes} bytes) -> ${htmlFileBytes.length} total`);
  return htmlFileBytes;
}

// expects htmlFileBytes is preprocessed
async function putOneBytes (host, privKeyHex, htmlFileBytes, pubKeyHex) {
  const unmodifiedSince = umsDate.toUTCString();
  const sigBytes = await ed.sign(htmlFileBytes, privKeyHex);
  const sigHex = Buffer.from(sigBytes).toString('hex');
  const fetchUri = `${host}/${pubKeyHex}`;
  const fetchRes = await fetch(fetchUri, {
    method: 'PUT',
    headers: {
      'content-type': constants.contentType,
      [constants.headerNames.version]: constants.protocolVersion,
      'if-unmodified-since': unmodifiedSince,
      [constants.headerNames.signature]: sigHex
    },
    body: htmlFileBytes
  });

  if (!fetchRes.ok) {
    console.error(`ERROR: ${host} ${fetchRes.status} "${fetchRes.statusText}"`);
  } else {
    console.log(`${host} PUT ${fetchUri} ${fetchRes.status}`);
  }
}

async function putOne (host, privKeyHex, htmlFile) {
  const pubKeyHex = Buffer.from(await ed.getPublicKey(privKeyHex)).toString('hex');
  const htmlFileBytes = await preprocess(fs.readFileSync(htmlFile), pubKeyHex);
  return putOneBytes(host, privKeyHex, htmlFileBytes, pubKeyHex);
}

async function main () {
  if (process.argv.length === 4) {
    let [,, boardsPath, postToHostsCSV] = process.argv;
    postToHostsCSV = postToHostsCSV.split(',');

    const boardKeys = await findKnownKeys(path.resolve(boardsPath), true);
    console.log(`Posting ${Object.keys(boardKeys).length} boards to: ${postToHostsCSV.join(', ')}`);

    await Promise.all(Object.entries(await findKnownKeys(path.resolve(boardsPath), true))
      .map(async ([, { body, metadata }]) => {
        const bodyPreProc = await preprocess(body, metadata.public);
        return await Promise.all(postToHostsCSV.map(async (host) =>
          await putOneBytes(host, metadata.private, bodyPreProc, metadata.public)));
      }));

    process.exit(0);
  }

  if (process.argv.length !== 5) {
    console.log(`To put a single board: ${process.argv[1]} host privKeyHex htmlFile`);
    console.log(`To put path of boards: ${process.argv[1]} boardPath hostsCommaSeperated`);
    process.exit(0);
  }

  await putOne(...process.argv.slice(2));
}

main();
